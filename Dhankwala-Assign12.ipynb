{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will continue working on image classification using PyTorch.\n",
    "* Download the intel image dataset from Kaggle.\n",
    "* We will use the OpenCV image feature extraction library. \n",
    "`(conda install -c conda-forge opencv)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. [10 pts] Download the dataset, unzip and explore the file folders. Load the image dataset \n",
    "with training and testing grouped. (Note, `cv2` reads and saves in BGR channel order)\n",
    "\n",
    "Display a few images. How many color channels are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "IMGSIZE = (128, 128)\n",
    "CNAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "def get_images_labels (path):\n",
    "    images, labels = [], []\n",
    "    label_dict = {}\n",
    "    label_count = 0\n",
    "    for label_folder in os.listdir(path):\n",
    "        real_path = os.path.join(path, label_folder)\n",
    "        if not os.path.isdir(real_path): continue\n",
    "        if label_folder not in label_dict:\n",
    "            label_dict[label_folder] = label_count\n",
    "            label_count += 1\n",
    "        for f in os.listdir(real_path):\n",
    "            img_path = os.path.join(real_path, f)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, IMGSIZE)\n",
    "                images.append(img)\n",
    "                labels.append(label_dict[label_folder])\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "X_tr, y_tr, X_ts, y_ts = [], [], [], []\n",
    "train_dir = 'seg_train/seg_train/'\n",
    "test_dir = 'seg_test/seg_test/'\n",
    "X_tr, y_tr = get_images_labels(train_dir)\n",
    "X_ts, y_ts = get_images_labels(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(X_tr):\n",
    "    cv2.imshow(f'Image - {y_tr[i]}', img)\n",
    "    cv2.waitKey(1)  # Display each image for 1ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [30 pts] Convert the imageset to numpy array, such as the array size:\n",
    "(14034, 128, 128, 3)\n",
    "Scale the imageset to [0-1].\n",
    "Build a regular fully connected neural network and report its performance on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale image to 0-1\n",
    "X_tr = X_tr.astype('float32') / 255.0\n",
    "X_ts = X_ts.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the images for the fully connected network\n",
    "X_tr_flat = X_tr.reshape(X_tr.shape[0], -1)\n",
    "X_ts_flat = X_ts.reshape(X_ts.shape[0], -1)\n",
    "\n",
    "# Build the neural network\n",
    "model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(128 * 128 * 3,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_tr)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_tr_flat, y_tr, epochs=10, validation_data=(X_ts_flat, y_ts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network\n",
    "neural_model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(128 * 128 * 3,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_tr)), activation='softmax')\n",
    "])\n",
    "# Flatten the images for the fully connected network\n",
    "X_tr_flat = X_tr.reshape(X_tr.shape[0], -1)\n",
    "X_ts_flat = X_ts.reshape(X_ts.shape[0], -1)\n",
    "\n",
    "build_neural_network(X_tr_flat, X_ts_flat, y_tr, y_ts, neural_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [40 pts] Create a convolutional neural network (CNN) to train and report its performance on \n",
    "the testing portion of the dataset. 95% reclassification and 75% testing performance should \n",
    "be achievable without any hyperparameter tuning. (Hint: My model, which is similar to the \n",
    "model in module notebook, took around 10 minutes to train 10 epochs without a GPU.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_tr)), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_tr, y_tr, epochs=10, batch_size=32, validation_data=(X_ts, y_ts))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_ts, y_ts)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 pts] Add regularization and/or drop-out features to your CNN. Report your model's best \n",
    "performance. As the performance standard deviation decreases the model is deemed to be \n",
    "more robust. Why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
